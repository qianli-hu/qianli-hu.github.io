<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
    
	<head>
		<title> Ruilin Li  &middot;  Machine Learning @ Georgia Tech</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<meta name="description" content="This is Ruilin Li's homepage" />
		<meta name="keywords" content="Ruilin Li, Georgia Tech, Machine Learning" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="/ruilin-li.github.io/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="css/ie8.css" /><![endif]-->
		<link rel="shortcut icon" href="/ruilin-li.github.io/images/favicon.ico" type="image/x-icon">
		<link rel="icon" href="/ruilin-li.github.io/images/favicon.ico" type="image/x-icon">
	</head>
		
    <body>
        <!-- Header -->
    <section id="header" class="skel-layers-fixed">
        <header>
            <span class="image avatar"><img src="/ruilin-li.github.io/images/avatar.jpg" alt="" /></span>
            <h1 id="logo"><a href="/ruilin-li.github.io/">Ruilin Li @ GT</a></h1>
            <p>Programmer, Researcher, Thinker</p>
        </header>
        <nav id="nav">
            <ul class="icons">
                <li><a href="/ruilin-li.github.io/index.html/#About" class="active">About</a></li>
                <!-- <li><a href="/ruilin-li.github.io/News">News</a></li> -->
                <!-- <li><a href="/ruilin-li.github.io/Publication">Publication</a></li> -->
                <li><a href="/ruilin-li.github.io/index.html/#Blog">Blog</a></li>
                <li><a href="/ruilin-li.github.io/index.html/#Miscellaneous">Miscellaneous</a></li>
                <li><a href="/ruilin-li.github.io/index.html/#Contact">Contact</a></li>
            </ul>
        </nav>
        <footer>
            <ul class="icons">
                <li><a href="http://github.com/ruilin-li" class="icon fa-github"><span class="label">Github</span></a></li>
                <li><a href="mailto:ruilin.li@gatech.edu" class="icon fa-envelope"><span class="label">Email</span></a></li>
                <li><a href="https://www.linkedin.com/in/ruilin-li-b71448bb/" class="icon fa-linkedin"><span class="label">Linkedin</span></a></li>
            </ul>
        </footer>
    </section>


        <div id="wrapper">
            <!-- Main -->
            <div id="main">
                <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async>
</script>

<section>
    <div class="container">
        <header class="major">
            <h2>One Paper a Day</h2>
                <p class="post-meta">Mar 22, 2017 • Ruilin Li</p>
        </header>

        <section class="post-content">
            <p>Inspired by <a href="https://medium.com/@nealjean/2017-challenge-one-paper-a-day-9d7811accd09#.wqq4ozcim">Neal Jean’s post</a>, I decide to start my 2017 challenge, try to read one paper per day to keep track of the latest progress in the area of machine learning.</p>

<ul>
  <li>
    <h3 id="towards-principled-methods-for-training-generative-adversarial-networks"><a href="https://arxiv.org/pdf/1701.04862.pdf">Towards Principled Methods for Training Generative Adversarial Networks</a></h3>
    <p>Martin Arjovsky, Léon Bottou - Read on Mar 23, 2017</p>
  </li>
</ul>

<p>Even if the real data generating distribution <script type="math/tex">P_{real}</script> and the fake generating distribution <script type="math/tex">P_g</script> lie on two arbitrarily close manifolds, under mild conditions, 
<script type="math/tex">JS(P_{real} || P_g) = \log 2</script>,
meaning that essentially, this distance measure of two probability distributions is not ‘continuous’. Moreover, the existence of optimal discriminator causes vanishing gradients on genrator. When switching to <script type="math/tex">-\log D</script> alternative, the gradient has infinite variance, impling unstable training. The remedy could be either add noise to descriminator or using softer distance measure such as <em>Wasserstein</em>.</p>

<ul>
  <li>
    <h3 id="wasserstein-gan"><a href="https://arxiv.org/pdf/1701.07875.pdf">Wasserstein GAN</a></h3>
    <p>Martin Arjovsky, Soumith Chintala, L´eon Bottou - Read on Mar 22, 2017</p>
  </li>
</ul>

<p><em>Wasserstein distance</em> is  weaker than <em>Total Variance Distance (TV)</em> and <em>Jenson-Shannon Divergence (JS)</em>. Moreover, all above three metric are weaker than <em>Kullback-Leibler Divergence (KL)</em>. A weaker distance metric induces a weaker topology in the space of all probability measures, a favorable setting for common gradient-based optimization algorithms, where convergence is easier in weak topology. The intractability of Wasserstein distance can be resolved by using <em>Kantorovich-Rubinstein duality</em> and then we can optimize it over parameterized functions. Empirical results show that WGAN enjoys strong stability and is more robust to various network architechtures.</p>


        </section>
        
        <footer>
            
            
        </footer>

    </div>

</section>


            </div>
            <!-- Footer -->
    <section id="footer">
        <div class="container">
            <ul class="copyright">
                <li>&copy; Ruilin Li 2017. All rights reserved.</li>
            </ul>
        </div>
    </section>

		</div>
	</body>
</html>