<!DOCTYPE HTML>
<!--
    Read Only by HTML5 UP
    html5up.net | @n33co
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
    
    <head>
        <title> Ruilin Li  &middot;  Machine Learning @ Georgia Tech</title>
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="description" content="This is Ruilin Li's homepage" />
        <meta name="keywords" content="Ruilin Li, Georgia Tech, Machine Learning" />
        <!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
        <link rel="stylesheet" href="/ruilin-li.github.io/css/main.css" />
        <!--[if lte IE 8]><link rel="stylesheet" href="css/ie8.css" /><![endif]-->
        <link rel="shortcut icon" href="/ruilin-li.github.io/images/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/ruilin-li.github.io/images/favicon.ico" type="image/x-icon">
    </head>
        
    <body>
        <!-- Header -->
<section id="header" class="skel-layers-fixed">
    <header>
        <span class="image avatar"><img src="/ruilin-li.github.io/images/avatar.jpg" alt="" /></span>
        <h1 id="logo"><a href="/ruilin-li.github.io/">Ruilin Li @ GT</a></h1>
        <p>Programmer, Researcher, Thinker</p>
    </header>
    <nav id="nav">
        <ul class="icons">
            <li><a href="/ruilin-li.github.io/index.html" class="active">Back to Mainpage</a></li>
        </ul>
    </nav>
    <footer>
        <ul class="icons">
            <li><a href="http://github.com/ruilin-li" class="icon fa-github"><span class="label">Github</span></a></li>
            <li><a href="mailto:ruilin.li@gatech.edu" class="icon fa-envelope"><span class="label">Email</span></a></li>
            <li><a href="https://www.linkedin.com/in/ruilin-li-b71448bb/" class="icon fa-linkedin"><span class="label">Linkedin</span></a></li>
        </ul>
    </footer>
</section>


        <div id="wrapper">
            <!-- Main -->
            <div id="main">
                <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>

                <section>
                    <div class="container">
                        <header class="major">
                            <h2>One Paper a Day</h2>
                                <p class="post-meta">Mar 22, 2017 • Ruilin Li</p>
                        </header>

                        <section class="post-content">
                            <p>Inspired by <a href="https://medium.com/@nealjean/2017-challenge-one-paper-a-day-9d7811accd09#.wqq4ozcim">Neal Jean’s post</a>, I decide to start my 2017 challenge, try to read one paper per day to keep track of the latest progress in the area of machine learning.</p>

<ul>
  <li>
    <h3 id="algorithms-for-inverse-reinforcement-learning"><a href="http://ai.stanford.edu/~ang/papers/icml00-irl.pdf">Algorithms for Inverse Reinforcement Learning</a></h3>

    <p>Andrew Y. Ng, Stuart Russell - Read on May 22, 2017</p>
  </li>
</ul>

<p>This paper did extensive experiments on sampling a representative sub-graph from a large graph. The authors proposed two types of goals - scale-down goal and back-in-time goal. The experiments showed that overall, random walk sampling and ‘forest fire’ sampling perform best, match most static and dynamic graph patterns well.</p>

<ul>
  <li>
    <h3 id="sampling-from-large-graphs"><a href="https://cs.stanford.edu/people/jure/pubs/sampling-kdd06.pdf">Sampling from Large Graphs</a></h3>
    <p>Jure Leskovic, Christos Faloutsos - Read on Mar 30, 2017</p>
  </li>
</ul>

<p>This paper did extensive experiments on sampling a representative sub-graph from a large graph. The authors proposed two types of goals - scale-down goal and back-in-time goal. The experiments showed that overall, random walk sampling and ‘forest fire’ sampling perform best, match most static and dynamic graph patterns well.</p>

<ul>
  <li>
    <h3 id="automatic-chemical-design-using-a-data-driven-continuous-representation-of-molecules"><a href="https://arxiv.org/pdf/1610.02415.pdf">Automatic chemical design using a data-driven continuous representation of molecules</a></h3>
    <p>Rafael Gomez-Bombarelli, David Duvenaud, Jose Miguel, Hernandez-Lobato, Jorge Aguilera-Iparraguirre, Timothy D. Hirzel, Ryan P. Adams, and Alan Aspuru-Guzik - Read on Mar 29, 2017</p>
  </li>
</ul>

<p>The idea of this paper is inspiring. Casting combinatoric object to an auto encoder, we can work with its latent, continuous, low dimensional(compared to original encoding) representation, where we have a great deal of powerful continuous optimization tools instead of local search for discrete structure. However, one difficulty needs to be addressed, once we have a latent representation, how we can make sure it is a valid one? What if it encodes to a non-exist combinatoric structure?</p>

<ul>
  <li>
    <h3 id="towards-principled-methods-for-training-generative-adversarial-networks"><a href="https://arxiv.org/pdf/1701.04862.pdf">Towards Principled Methods for Training Generative Adversarial Networks</a></h3>
    <p>Martin Arjovsky, Léon Bottou - Read on Mar 23, 2017</p>
  </li>
</ul>

<p>Even if the real data generating distribution <script type="math/tex">P_{real}</script> and the fake generating distribution <script type="math/tex">P_g</script> lie on two arbitrarily close manifolds, under mild conditions, <script type="math/tex">JS(P_{real} \| P_g) = \log 2</script>, meaning that essentially, this distance measure of two probability distributions is not ‘continuous’. Moreover, the existence of optimal discriminator causes vanishing gradients on generator. When switching to <script type="math/tex">-\log D</script> alternative, the gradient has infinite variance, implying unstable training. The remedy could be either adding noise to discriminator or using softer distance measure such as <em>Wasserstein</em>.</p>

<ul>
  <li>
    <h3 id="wasserstein-gan"><a href="https://arxiv.org/pdf/1701.07875.pdf">Wasserstein GAN</a></h3>
    <p>Martin Arjovsky, Soumith Chintala, L´eon Bottou - Read on Mar 22, 2017</p>
  </li>
</ul>

<p><em>Wasserstein distance</em> is  weaker than <em>Total Variance Distance (TV)</em> and <em>Jenson-Shannon Divergence (JS)</em>. Moreover, all above three metric are weaker than <em>Kullback-Leibler Divergence (KL)</em>. A weaker distance metric induces a weaker topology in the space of all probability measures, a favorable setting for common gradient-based optimization algorithms, where convergence is easier in weak topology. The intractability of Wasserstein distance can be resolved by using <em>Kantorovich-Rubinstein duality</em> and then we can optimize it over parameterized functions. Empirical results show that WGAN enjoys strong stability and is more robust to various network architectures.</p>

<ul>
  <li>
    <h3 id="generative-adversarial-nets"><a href="https://arxiv.org/pdf/1406.2661.pdf">Generative Adversarial Nets</a></h3>
    <p>Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair†, Aaron Courville, Yoshua Bengio - Read on Mar 21, 2017</p>
  </li>
</ul>

<p><em>GAN</em> combines generative model and discriminative model, simultaneously training two neural networks to learn the generating probability of the data. The value function to maximize here is</p>

<script type="math/tex; mode=display">\displaystyle \min_{G}\max_{D} V(D,G) = \mathbb{E}_{\boldsymbol{x} \sim p_{data}(\boldsymbol{x})} [\log D(\boldsymbol{x})] - \mathbb{E}_{\boldsymbol{x} \sim p_{x}(\boldsymbol{x})} [\log D(\boldsymbol{x})]</script>

<p>and the paper showed convergence of the algorithm under reasonable condition. Actually, this creative framework can be extended to train various generative models.</p>

                        </section>
                        
                        <footer>
                            
                            
                        </footer>

                    </div>

                </section>
   




    

<!-- Scripts -->
<script src="/ruilin-li.github.io/js/jquery.min.js"></script>
<script src="/ruilin-li.github.io/js/jquery.scrollzer.min.js"></script>
<script src="/ruilin-li.github.io/js/jquery.scrolly.min.js"></script>
<script src="/ruilin-li.github.io/js/skel.min.js"></script>
<script src="/ruilin-li.github.io/js/util.js"></script>
<!--[if lte IE 8]><script src="js/ie/respond.min.js"></script><![endif]-->
<script src="/ruilin-li.github.io/js/main.js"></script>



            </div>
            <!-- Footer -->

<section id="footer">
    <div class="container">
        <ul class="copyright">
            <li>&copy; Ruilin Li 2017. All rights reserved.</li>
        </ul>
    </div>
</section>

        </div>
    </body>
</html>